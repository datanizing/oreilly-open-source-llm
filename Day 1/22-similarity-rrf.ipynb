{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da3f9f6-7853-4bda-b29f-c07bf859d0e2",
   "metadata": {},
   "source": [
    "# Reciprocal rank fusion\n",
    "\n",
    "As you have seen in the previous notebooks, we now have several result lists:\n",
    "* Semantic results from different embeddings models\n",
    "* Lexical results from `tantivy`\n",
    "\n",
    "Unfortunately, the scores of these lists are *incommensurable*. We cannot use the\n",
    "score for sorting. However, we can use the *rank* as an indicator in each list\n",
    "how well the documents are matching. This is universal. Here, we implement\n",
    "an alogrithm which *fuses* these result lists using only the rank in the\n",
    "individual lists, not the score.\n",
    "\n",
    "The formula for calculating the fused score is $ {\\rm score} = \\sum \\frac{1}{k + {\\rm rank}} $ \n",
    "with $k=60$. The heart of the notebook is the function `rrf` which iterates over a\n",
    "unique list of all document ids and calculates the scores with the formula above.\n",
    "\n",
    "We try the algorithm with many different result lists (semantic with different models\n",
    "and lexical)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ece1d-7558-4fb6-a98b-ad06283bb898",
   "metadata": {},
   "source": [
    "## Load data (from previous notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08c809-10c6-42aa-9a01-0477ca426b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"sentences.json\") as f:\n",
    "    sentences = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73220da2-6d8f-42db-95ac-f361449388b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a656b2-e292-47e4-8c91-066acbf77186",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d13cb7a-1325-4059-af8c-bbd026ce9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open(\"sentences-mqa.npy\", \"rb\") as f:\n",
    "    sembeddings = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1b2b1-9072-4b60-b8c4-4130b8f8d6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d690106a-8751-48c5-80b1-af6078a2a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def search_semantic(query, text, corpus_embeddings, model, query_prompt_name=None, top=20):\n",
    "    # code query to restrict search space\n",
    "    question_embedding = model.encode(query, normalize_embeddings=True, prompt_name=query_prompt_name)\n",
    "    \n",
    "    # Determine similarity (vectors are normalized)\n",
    "    sim = model.similarity(question_embedding, corpus_embeddings)[0].numpy() \n",
    "    # Alternative: sim = np.dot(corpus_embeddings, question_embedding)\n",
    "    \n",
    "    # Get most similar top_k by sorting\n",
    "    hits = [ { \"id\": i, \"text\": text[i], \"score\": sim[i] } \n",
    "                     for i in sim.argsort()[::-1][0:top] ]\n",
    "    \n",
    "    # Return as dataframe\n",
    "    return pd.DataFrame(hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917fb2cb-b73c-42d5-a64f-9af83322947a",
   "metadata": {},
   "source": [
    "remove a possible old index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29833590-c205-41e1-9c53-eefda89afbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tantivy\n",
    "schema_builder = tantivy.SchemaBuilder()\n",
    "schema_builder.add_integer_field(\"id\", stored=True)\n",
    "schema_builder.add_text_field(\"text\", stored=True)\n",
    "schema = schema_builder.build()\n",
    "index = tantivy.Index(schema, \"tantivy-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e0a9f-aa02-47a8-8d92-d600def1c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_lexical(query, index, top=20):\n",
    "    searcher = index.searcher()\n",
    "    query = index.parse_query(query, [\"text\"])\n",
    "    search_results = searcher.search(query, limit=20).hits\n",
    "    res = []\n",
    "    for (score, doc_id) in search_results:\n",
    "        doc = searcher.doc(doc_id)\n",
    "        res.append({ \"id\": doc[\"id\"][0], \"text\": doc[\"text\"][0], \"score\": score })\n",
    "\n",
    "    return(pd.DataFrame(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a992863-4b45-43ab-8119-e00f1d6aaa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is the climate crisis worse in poorer countries?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b40f6-5fa7-4bd0-82d4-153329cb62ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d1dd83-117b-41a0-93e8-16ed484e42c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic search dataframe\n",
    "sdf = search_semantic(question, sentences, sembeddings, model).set_index(\"id\")\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddee250-b138-4f7e-a112-ca9e3af21adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexical search dataframe\n",
    "ldf = search_lexical(question, index).set_index(\"id\")\n",
    "ldf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d8b6b0-558f-46e9-a835-f7d86d36709c",
   "metadata": {},
   "source": [
    "### Reciprocal rank fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb6a8f-49a9-4666-ba9d-61a24a71cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def rrf(dataframes):\n",
    "    docs = []  # list of matching docs\n",
    "    ranks = [] # ranks for each document in the separate lists\n",
    "    ids = []   # list of unique ids\n",
    "    for df in dataframes:\n",
    "        ids += list(df.index)\n",
    "    # only use each id once\n",
    "    for i in np.unique(ids):\n",
    "        # the score\n",
    "        s = 0\n",
    "        # we also want to record the rank for debugging and visualization\n",
    "        rank = []\n",
    "        for df in dataframes:\n",
    "            # if the current id is in the index\n",
    "            if i in df.index:\n",
    "                # calculate the scoree and add \n",
    "                s += 1 / (60.0 + list(df.index).index(i)+1)\n",
    "                rank.append(list(df.index).index(i)+1)\n",
    "            else:\n",
    "                rank.append(None)\n",
    "\n",
    "        # append to the list of docs, including the score and the rank list\n",
    "        docs.append({ \"id\": i, \"text\": sentences[i], \"score\": s })\n",
    "        ranks.append(rank)\n",
    "\n",
    "    # convert to a dataframe\n",
    "    df = pd.DataFrame(docs)\n",
    "    df[[f\"result_{i}\" for i in range(len(dataframes))]] = ranks\n",
    "    return df.set_index(\"id\").sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b41676d-35b3-403f-bb5d-ca5cdcac71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the rank fusion for semantic and lexical search\n",
    "rrf([sdf, ldf]).style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88cec7e-444a-40a9-aa4d-ea8f182b0777",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = SentenceTransformer('google/embeddinggemma-300m')\n",
    "with open(\"sentences-gemma.npy\", \"rb\") as f:\n",
    "    sembeddings2 = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06127e00-ca67-450e-a09a-cc9761a38abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = SentenceTransformer(\"Snowflake/snowflake-arctic-embed-l-v2.0\", trust_remote_code=True)\n",
    "with open(\"sentences-arctic.npy\", \"rb\") as f:\n",
    "    sembeddings3 = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfc00de-f558-4bcc-91d6-e70b9e05bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf2 = search_semantic(\"task: search result | query:\" + question, \n",
    "                       sentences, sembeddings2, model2).set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e6c8e-3623-4e8e-b0b4-eebfe5dfe0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf3 = search_semantic(question, \n",
    "                       sentences, sembeddings3, model3, query_prompt_name=\"query\").set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d1239-0dcf-478d-a39a-28ca0df733fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrf([ldf, sdf, sdf2, sdf3]).head(20).style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f6579c-378f-43e2-a508-2875e0a948f5",
   "metadata": {},
   "source": [
    "if you think the result is *spoiled* by the lexical matches, use only semantic matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b063581-32cb-4669-bdde-65308ce2ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrf([sdf, sdf2, sdf3]).head(20).style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6102c14-cefe-4537-8b22-801d08bf741a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollm",
   "language": "python",
   "name": "ollm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
