{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59bc0de5-d3c1-4ea6-a293-630c99fd22fd",
   "metadata": {},
   "source": [
    "# Calculating similarity with an embedding model including retrieval\n",
    "\n",
    "This notebook uses the sentences from the UN general debate which were segmented in the [last notebook](10-prepare-data.ipynb). \n",
    "\n",
    "We will use different models for vectorizing the sentences (i.e. calculating the embeddings):\n",
    "* multi-qa-MiniLM-L6-cos-v1 is recommended by [SBERT](https://sbert.net)\n",
    "* embeddinggemma-300m is a small, but powerful model from Google\n",
    "* snowflake-arctic-embed-l-v2.0 is ranked quite high on the [MTEB](https://huggingface.co/spaces/mteb/leaderboard)\n",
    "\n",
    "The actual calculation can take from seconds to minutes, depending on the hardware. To save this time later, we save the embeddings in `numpy` format.\n",
    "\n",
    "After this, the retrieval takes place. The retrieval function is documented with extensive comments. Notice the different ways of how questions can be differentiated from possible answers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ece1d-7558-4fb6-a98b-ad06283bb898",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23bb98c-f62d-4c3a-af7e-8357f9398fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"sentences.json\") as f:\n",
    "    sentences = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ac753-3f5d-4eed-a51b-581c37856041",
   "metadata": {},
   "source": [
    "## Encode sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1886a74-5b2c-4eaa-aff0-dba0c2c73747",
   "metadata": {},
   "source": [
    "Sentence Bert can be found at https://sbert.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1b2b1-9072-4b60-b8c4-4130b8f8d6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259f42b-9c45-4fee-b319-afcb37625ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take a minute or two depending on CPU/GPU configuration\n",
    "sembeddings = model.encode(sentences, show_progress_bar=True, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734a5b8-8175-4dff-b860-eef739e26cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sembeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a361c-959b-4fe7-b8c0-241087391e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sembeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb009d-7d0a-4332-a29d-68aea47e2f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open(\"sentences-mqa.npy\", \"wb\") as f:\n",
    "    np.save(f, sembeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5a8bd9-1832-4bcb-a3af-21037cb1ad8b",
   "metadata": {},
   "source": [
    "Many more models are available on Hugging Face.\n",
    "\n",
    "Benchmark of models: https://huggingface.co/spaces/mteb/leaderboard\n",
    "\n",
    "Search for all sentence similarity models: https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9da252-184c-424a-8166-e7646687814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# superfast alternative using ModelVec, speedup 400x CPU to 25x GPU:\n",
    "# you can try it, but it is more focused on lexical than semantic retrieval\n",
    "model_fast = SentenceTransformer(\"minishlab/potion-base-8M\", device=\"cpu\")\n",
    "sembeddings_fast = model_fast.encode(sentences, show_progress_bar=True, \n",
    "                             normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e38bd",
   "metadata": {},
   "source": [
    "### Alternative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0c72c-c122-40ec-b0b0-9adbb6fb124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option: truncate_dim=dimensions\n",
    "# option for cpu: backend=\"openvino\"\n",
    "model2 = SentenceTransformer('google/embeddinggemma-300m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4687ef-fcc7-4c1a-adae-cbbb7035d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take a minute or two depending on CPU/GPU configuration\n",
    "sembeddings2 = model2.encode(sentences, show_progress_bar=True, \n",
    "                             normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c12bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sembeddings2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b75ba-94ed-4de9-9610-d03410448bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we wanted, we could now quantize the embeddings to save space and add performance:\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "binary_embeddings2 = quantize_embeddings(sembeddings2, precision=\"ubinary\")\n",
    "binary_embeddings2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00be3e0-780a-4916-860f-1b965f301e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sentences-gemma.npy\", \"wb\") as f:\n",
    "    np.save(f, sembeddings2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd753ea3",
   "metadata": {},
   "source": [
    "## One more alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25caf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = SentenceTransformer(\"Snowflake/snowflake-arctic-embed-l-v2.0\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e3cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sembeddings3 = model3.encode(sentences, show_progress_bar=True, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f21b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "sembeddings3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87590881",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sentences-arctic.npy\", \"wb\") as f:\n",
    "    np.save(f, sembeddings3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da8f067-aea3-4f3d-82a9-67d1472ad446",
   "metadata": {},
   "source": [
    "## `Qwen/Qwen3-Embedding-0.6B` ranks really well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410e0de-6871-43df-ae00-bc829ca8e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = SentenceTransformer(\"Qwen/Qwen3-Embedding-0.6B\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0220bca4-31f9-487c-9f34-351540742800",
   "metadata": {},
   "outputs": [],
   "source": [
    "sembeddings4 = model4.encode(sentences, show_progress_bar=True, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd12253-10ee-4e5b-84d9-32b0ab23a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "sembeddings4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86d22f-8ac3-4db1-98da-93a5af97896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sentences-qwen.npy\", \"wb\") as f:\n",
    "    np.save(f, sembeddings4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dddad02-fea3-40a0-b9b2-eb4ad04f910b",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416ac725-97c8-4709-aad3-f36cac16a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, text, corpus_embeddings, model, query_prompt_name=None, top=20):\n",
    "    # code query to restrict search space\n",
    "    question_embedding = model.encode(query, normalize_embeddings=True, prompt_name=query_prompt_name)\n",
    "    \n",
    "    # Determine similarity (vectors are normalized)\n",
    "    sim = model.similarity(question_embedding, corpus_embeddings)[0].numpy() \n",
    "    # Alternative: sim = np.dot(corpus_embeddings, question_embedding)\n",
    "    \n",
    "    # Get most similar top_k by sorting\n",
    "    hits = [ { \"id\": i, \"text\": text[i], \"score\": sim[i] } \n",
    "                     for i in sim.argsort()[::-1][0:top] ]\n",
    "    \n",
    "    # Return as dataframe\n",
    "    return pd.DataFrame(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a0f3f-6a10-406e-938c-ff7573787206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed14fc30-5640-4891-8ae1-defa57bf21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1df = search(\"Is the climate crisis worse for poorer countries?\", sentences, sembeddings, model)\n",
    "m1df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a43d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2adf = search(\"Is the climate crisis worse for poorer countries?\", sentences, sembeddings2, model2)\n",
    "m2adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ed46d-024f-46ae-89a4-9bc29fea854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2bdf = search(\"task: search result | query: Is the climate crisis worse for poorer countries?\", sentences, sembeddings2, model2)\n",
    "m2bdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f2c61d-9f8b-4425-b9d1-b4a465e7f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference is big\n",
    "set(m2bdf[\"id\"]).symmetric_difference(set(m2adf[\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd9ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3adf = search(\"Is the climate crisis worse for poorer countries?\", sentences, sembeddings3, model3)\n",
    "m3adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d6315-e7fb-4b60-be4f-0c754b24bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3bdf = search(\"Is the climate crisis worse for poorer countries?\", sentences, sembeddings3, model3, \n",
    "               query_prompt_name=\"query\")\n",
    "m3bdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again a big difference in matches\n",
    "set(m3bdf[\"id\"]).symmetric_difference(set(m3adf[\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ffdb47-0ba9-4114-9721-ed5bb6d27e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4adf = search(\"Is the climate crisis worse for poorer countries?\", sentences, sembeddings4, model4)\n",
    "m4adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a898972b-7159-4623-86f2-1b53165d0ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4bdf = search(\"Is the climate crisis worse for poorer countries?\", sentences, sembeddings4, model4, \n",
    "               query_prompt_name=\"query\")\n",
    "m4bdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e23606c-fd1d-49e8-8333-e4748eaabac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only a minor difference in matches\n",
    "set(m4bdf[\"id\"]).symmetric_difference(set(m4adf[\"id\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollm",
   "language": "python",
   "name": "ollm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
