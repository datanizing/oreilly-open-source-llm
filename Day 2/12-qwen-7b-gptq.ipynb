{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20924265-8d47-46fd-b8d8-899562b851cc",
   "metadata": {},
   "source": [
    "# Using the Qwen language model with GPTQ quantization\n",
    "\n",
    "Originally, this notebook contained code to run a GPTQ-quantized\n",
    "language model. In earlier version of the `transformers` library,\n",
    "this was even integrated there.\n",
    "\n",
    "This is not useful anymore. There are more powerful quantization\n",
    "techniques and the support of GPTQ has been discontinued. If you\n",
    "really want to run these models, you can use the `vllm` framework\n",
    "which we will introduce a bit later.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollm",
   "language": "python",
   "name": "ollm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
