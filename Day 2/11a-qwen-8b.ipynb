{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c783194-a9b1-4619-85d2-aa7543190e6f",
   "metadata": {},
   "source": [
    "# Generate text using the model Qwen-8B\n",
    "\n",
    "In this notebook, we use the generative large language model\n",
    "[Qwen-8B](https://huggingface.co/Qwen/Qwen3-8B). This is a hybrid model\n",
    "which can use \"thinking\" mode, but it is also possible to omit it.\n",
    "\n",
    "Qwen-8B has 8 billion parameters, so with 2 bytes per parameter\n",
    "(`bfloat16`) we expect a memory usage of 16 GB.\n",
    "\n",
    "We will use the chat template for Qwen-8B and different prompts. You\n",
    "can observe the behavior from LLMs that they produce different answers\n",
    "for the same prompts. You will also see how can you can avoid that\n",
    "and get reproducible answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92465c5-4c6a-4e7d-abe3-f37aebdf5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_properties(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4a2b95-81fc-4339-8934-8bfda99c2f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen3-8B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a2bb5-dcb8-4559-bb36-5e3cc8f48a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf6e37-5a8e-4051-aafc-90ef7606e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollm",
   "language": "python",
   "name": "ollm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
